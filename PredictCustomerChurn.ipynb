{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Restarting the session and Clearning all temporary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from IPython import get_ipython\n",
    "    get_ipython().magic('clear')\n",
    "    get_ipython().magic('reset -f')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section A: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries for data analysis\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, skew\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "# sklearn modules for data preprocessing\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "\n",
    "# sklearn modules for Model Selection\n",
    "\n",
    "from sklearn import svm, tree, linear_model, neighbors\n",
    "from sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# sklearn modules for Model Evaluation & Improvement\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, fbeta_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import make_scorer, recall_score, log_loss\n",
    "from sklearn.metrics import average_precision_score\n",
    "  \n",
    "\n",
    "# standard libraries for data visualization\n",
    "\n",
    "import seaborn as sn\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib \n",
    "%matplotlib inline\n",
    "color = sn.color_palette()\n",
    "import matplotlib.ticker as mtick\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "\n",
    "# miscellaneous Utilitiy Libraries\n",
    "    \n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import timeit\n",
    "import string\n",
    "import time\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from dateutil.parser import parse\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set up current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste dataset path below\n",
    "\n",
    "os.chdir(r\"PASTE_PATH_OF_DATASET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('customer_churn_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate Datastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck Column Datatypes and Missing Values:\n",
    "    \n",
    "dataset.columns.to_series().groupby(dataset.dtypes).groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique values in each categorical variable:\n",
    "\n",
    "dataset[\"PaymentMethod\"].nunique()\n",
    "\n",
    "dataset[\"PaymentMethod\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Contract\"].nunique()\n",
    "\n",
    "dataset[\"Contract\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Check Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset[\"Churn\"].value_counts()\n",
    "\n",
    "\n",
    "# ======================================================================================================\n",
    "# in this case, we have class imbalance with few negatives. In our business challenge, \n",
    "# false negatives are costly. Hence let's keep an eye onto the Precision, Recall & F2 score besides accuracy\n",
    "# ======================================================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Clean the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset['TotalCharges'] = pd.to_numeric(dataset['TotalCharges'],errors='coerce')\n",
    "\n",
    "dataset['TotalCharges'] = dataset['TotalCharges'].astype(\"float\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Take care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the average and fill missing values programmatically\n",
    "na_cols = dataset.isna().any()\n",
    "na_cols = na_cols[na_cols == True].reset_index()\n",
    "na_cols = na_cols[\"index\"].tolist()\n",
    "for col in dataset.columns[1:]:\n",
    "     if col in na_cols:\n",
    "        if dataset[col].dtype != 'object':\n",
    "             dataset[col] =  dataset[col].fillna(dataset[col].mean()).round(0)\n",
    "                \n",
    "# revalidate NAâ€™s\n",
    "dataset.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: label Encode Binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# label encoding will be used for columns with 2 or less unique values\n",
    "le_count = 0\n",
    "for col in dataset.columns[1:]:\n",
    "    if dataset[col].dtype == 'object':\n",
    "        if len(list(dataset[col].unique())) <= 2:\n",
    "            le.fit(dataset[col])\n",
    "            dataset[col] = le.transform(dataset[col])\n",
    "            le_count += 1\n",
    "print('{} columns were label encoded.'.format(le_count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section B: Data Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9.1. Plot Histogram of numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset2 = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'tenure', 'PhoneService', 'PaperlessBilling',\n",
    "        'MonthlyCharges', 'TotalCharges']]\n",
    "\n",
    "# histogram:\n",
    "    \n",
    "fig = plt.figure(figsize=(15, 12))\n",
    "plt.suptitle('Histograms of Numerical Columns\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = 24, fontfamily = \"sans-serif\")\n",
    "for i in range(dataset2.shape[1]):\n",
    "    plt.subplot(6, 3, i + 1)\n",
    "    f = plt.gca()\n",
    "    f.set_title(dataset2.columns.values[i])\n",
    "\n",
    "    vals = np.size(dataset2.iloc[:, i].unique())\n",
    "    if vals >= 100:\n",
    "        vals = 100\n",
    "    \n",
    "    plt.hist(dataset2.iloc[:, i], bins=vals, color = '#ec838a')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9.2. Analyze distribution of Key Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (1) Distribution of Contract Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "contract_split = dataset[[ \"customerID\", \"Contract\"]]\n",
    "sectors = contract_split .groupby (\"Contract\")\n",
    "contract_split = pd.DataFrame(sectors[\"customerID\"].count())\n",
    "contract_split.rename(columns={'customerID':'No. of customers'}, inplace=True)\n",
    "\n",
    "\n",
    "ax =  contract_split[[\"No. of customers\"]].plot.bar(title = 'Customers by Contract Type', legend =True, table = False, grid = False,  subplots = False,  figsize =(12, 7), color ='#ec838a', fontsize = 15, stacked=False)\n",
    "\n",
    "plt.ylabel('No. of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('\\n Contract Type',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Customers by Contract Type \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc='upper right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "x_labels = np.array(contract_split[[\"No. of customers\"]])\n",
    "\n",
    "def add_value_labels(ax, spacing=5):   \n",
    "    for rect in ax.patches:      \n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2       \n",
    "        space = spacing        \n",
    "        va = 'bottom'      \n",
    "        if y_value < 0:           \n",
    "            space *= -1            \n",
    "            va = 'top'       \n",
    "        label = \"{:.0f}\".format(y_value)      \n",
    "        ax.annotate(\n",
    "            label,                      \n",
    "            (x_value, y_value),         \n",
    "            xytext=(0, space),          \n",
    "            textcoords=\"offset points\", \n",
    "            ha='center',                \n",
    "            va=va)                                                             \n",
    "add_value_labels(ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (2) Distribution of Payment Method Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "payment_method_split = dataset[[ \"customerID\", \"PaymentMethod\"]]\n",
    "sectors = payment_method_split  .groupby (\"PaymentMethod\")\n",
    "payment_method_split  = pd.DataFrame(sectors[\"customerID\"].count())\n",
    "payment_method_split.rename(columns={'customerID':'No. of customers'}, inplace=True)\n",
    "\n",
    "\n",
    "ax =  payment_method_split [[\"No. of customers\"]].plot.bar(title = 'Customers by Payment Method', legend =True, table = False, grid = False,  subplots = False,  figsize =(15, 10), color ='#ec838a', fontsize = 15, stacked=False)\n",
    "\n",
    "plt.ylabel('No. of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('\\n Contract Type',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Customers by Payment Method \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc='upper right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "x_labels = np.array(payment_method_split [[\"No. of customers\"]])\n",
    "\n",
    "def add_value_labels(ax, spacing=5):   \n",
    "    for rect in ax.patches:      \n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2       \n",
    "        space = spacing        \n",
    "        va = 'bottom'      \n",
    "        if y_value < 0:           \n",
    "            space *= -1            \n",
    "            va = 'top'       \n",
    "        label = \"{:.0f}\".format(y_value)      \n",
    "        ax.annotate(\n",
    "            label,                      \n",
    "            (x_value, y_value),         \n",
    "            xytext=(0, space),          \n",
    "            textcoords=\"offset points\", \n",
    "            ha='center',                \n",
    "            va=va)                                                             \n",
    "add_value_labels(ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (3) Distribution of various Label Encoded Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "services = ['PhoneService','MultipleLines','InternetService','OnlineSecurity',\n",
    "           'OnlineBackup','DeviceProtection','TechSupport','StreamingTV','StreamingMovies']\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 3,ncols = 3,figsize = (15,12))\n",
    "for i, item in enumerate(services):\n",
    "    if i < 3:\n",
    "        ax = dataset[item].value_counts().plot(kind = 'bar',ax=axes[i,0],rot = 0, color ='#f3babc' )\n",
    "        \n",
    "    elif i >=3 and i < 6:\n",
    "        ax = dataset[item].value_counts().plot(kind = 'bar',ax=axes[i-3,1],rot = 0,color ='#9b9c9a')\n",
    "        \n",
    "    elif i < 9:\n",
    "        ax = dataset[item].value_counts().plot(kind = 'bar',ax=axes[i-6,2],rot = 0,color = '#ec838a')\n",
    "    ax.set_title(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9.3: Analyze Churn Rate by Categorical variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### (1) Overall Churn Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.ticker as mtick\n",
    "churn_rate = dataset[[\"Churn\", \"customerID\"]]\n",
    "churn_rate [\"churn_label\"] = pd.Series(np.where((churn_rate[\"Churn\"] == 0), \"No\", \"Yes\"))\n",
    "sectors = churn_rate .groupby (\"churn_label\")\n",
    "churn_rate = pd.DataFrame(sectors[\"customerID\"].count())\n",
    "churn_rate [\"Churn Rate\"] = (churn_rate [\"customerID\"] / sum(churn_rate [\"customerID\"]) )*100\n",
    "ax =  churn_rate[[\"Churn Rate\"]].plot.bar(title = 'Overall Churn Rate', legend =True, table = False, grid = False,  subplots = False,  figsize =(12, 7), color = '#ec838a', fontsize = 15, stacked=False, ylim =(0,100))\n",
    "\n",
    "plt.ylabel('Proportion of Customers',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Churn',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Overall Churn Rate \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc='upper right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "x_labels = np.array(churn_rate[[\"customerID\"]])\n",
    "\n",
    "def add_value_labels(ax, spacing=5):   \n",
    "    for rect in ax.patches:     \n",
    "        y_value = rect.get_height()\n",
    "        x_value = rect.get_x() + rect.get_width() / 2       \n",
    "        space = spacing\n",
    "        va = 'bottom'        \n",
    "        if y_value < 0:           \n",
    "            space *= -1          \n",
    "            va = 'top'\n",
    "        \n",
    "        label = \"{:.1f}%\".format(y_value)    \n",
    "        ax.annotate(\n",
    "            label,                      \n",
    "            (x_value, y_value),        \n",
    "            xytext=(0, space),         \n",
    "            textcoords=\"offset points\", \n",
    "            ha='center',                \n",
    "            va=va)                                                            \n",
    "add_value_labels(ax)\n",
    "ax.autoscale(enable=False, axis='both', tight=False)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Churn Rate by Contract Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "contract_churn = dataset.groupby(['Contract','Churn']).size().unstack()\n",
    "\n",
    "contract_churn.rename(columns={0:'No', 1:'Yes'}, inplace=True)\n",
    "\n",
    "colors  = ['#ec838a','#9b9c9a']\n",
    "\n",
    "ax = (contract_churn.T*100.0 / contract_churn.T.sum()).T.plot(kind='bar',\n",
    "                                                                width = 0.3,\n",
    "                                                                stacked = True,\n",
    "                                                                rot = 0, \n",
    "                                                                figsize = (12,7),\n",
    "                                                                color = colors)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('Proportion of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Contract Type\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Churn Rate by Contract type \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc='upper right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.text(x+width/2, \n",
    "            y+height/2, \n",
    "            '{:.1f}%'.format(height), \n",
    "            horizontalalignment='center', \n",
    "            verticalalignment='center')\n",
    "ax.autoscale(enable=False, axis='both', tight=False)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) Churn Rate by Payment Method Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "contract_churn = dataset.groupby(['Contract','PaymentMethod']).size().unstack()\n",
    "\n",
    "contract_churn.rename(columns={0:'No', 1:'Yes'}, inplace=True)\n",
    "\n",
    "colors  = ['#ec838a','#9b9c9a', '#f3babc' , '#4d4f4c']\n",
    "\n",
    "ax = (contract_churn.T*100.0 / contract_churn.T.sum()).T.plot(kind='bar',\n",
    "                                                                width = 0.3,\n",
    "                                                                stacked = True,\n",
    "                                                                rot = 0, \n",
    "                                                                figsize = (12,7),\n",
    "                                                                color = colors)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('Proportion of Customers\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Contract Type\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Churn Rate by Payment Method \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc='upper right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.text(x+width/2, \n",
    "            y+height/2, \n",
    "            '{:.1f}%'.format(height), \n",
    "            horizontalalignment='center', \n",
    "            verticalalignment='center')\n",
    "ax.autoscale(enable=False, axis='both', tight=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9.4. Find positive and negative correlations with the Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset2 = dataset[['SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'tenure', 'PhoneService', 'PaperlessBilling',\n",
    "        'MonthlyCharges', 'TotalCharges']]\n",
    "\n",
    "correlations = dataset2.corrwith(dataset.Churn)\n",
    "correlations = correlations[correlations!=1]\n",
    "positive_correlations = correlations[correlations >0].sort_values(ascending = False)\n",
    "negative_correlations = correlations[correlations<0].sort_values(ascending = False)\n",
    "\n",
    "print('Most Positive Correlations: \\n', positive_correlations)\n",
    "print('\\nMost Negative Correlations: \\n', negative_correlations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlations = dataset2.corrwith(dataset.Churn)\n",
    "correlations = correlations[correlations!=1]\n",
    "\n",
    "correlations.plot.bar(\n",
    "        figsize = (18, 10), fontsize = 15, color = '#ec838a',\n",
    "        rot = 45, grid = True)\n",
    "\n",
    "plt.title('Correlation with Churn Rate \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9.5. Plot Correlation Matrix of all independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set and compute the Correlation Matrix\n",
    "sn.set(style=\"white\")\n",
    "corr = dataset2.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure and a diverging colormap\n",
    "f, ax = plt.subplots(figsize=(18, 15))\n",
    "cmap = sn.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sn.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9.6: Check Multicolinearity using VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)\n",
    "\n",
    "dataset2 = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'tenure', 'PhoneService', 'PaperlessBilling','MonthlyCharges','TotalCharges']]\n",
    "\n",
    "calc_vif(dataset2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Charges seem to be colinear with Monthly Charges.\n",
    "\n",
    "#check colinearity:\n",
    "    \n",
    "dataset2[['MonthlyCharges', 'TotalCharges']].plot.scatter(figsize = (15, 10), x = 'MonthlyCharges',\n",
    "                                                              y='TotalCharges', color =  '#ec838a')\n",
    "\n",
    "\n",
    "plt.title('Co-linearity of Monthly Charges and Total Charges \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dropping TotalCharges:\n",
    "    \n",
    "dataset2 = dataset2.drop(columns = \"TotalCharges\")\n",
    "\n",
    "#Revalidate Colinearity:\n",
    "\n",
    "dataset2 = dataset[['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'tenure', 'PhoneService', 'PaperlessBilling','MonthlyCharges']]\n",
    "\n",
    "calc_vif(dataset2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying changes in the main dataset:\n",
    "    \n",
    "dataset = dataset.drop(columns = \"TotalCharges\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Encode Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Incase if user_id is an object:\n",
    "    \n",
    "identity = dataset[\"customerID\"]\n",
    "\n",
    "dataset = dataset.drop(columns=\"customerID\")\n",
    "\n",
    "# convert rest of categorical variable into dummy\n",
    "\n",
    "dataset= pd.get_dummies(dataset)\n",
    "\n",
    "#Rejoin userid to dataset (column concatenation)\n",
    "\n",
    "dataset = pd.concat([dataset, identity], axis = 1)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Split dataset into dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#identify response variable:\n",
    "    \n",
    "response = dataset[\"Churn\"]\n",
    "\n",
    "dataset = dataset.drop(columns=\"Churn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Generate training and test datasets of dependent and independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset, response,\n",
    "                                                    stratify=response, \n",
    "                                                    test_size = 0.2, #use 0.9 if data is huge.\n",
    "                                                    random_state = 0)\n",
    "\n",
    "#to resolve any class imbalance - use stratify parameter.\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Removing Identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_identity = X_train['customerID']\n",
    "X_train = X_train.drop(columns = ['customerID'])\n",
    "\n",
    "test_identity = X_test['customerID']\n",
    "X_test = X_test.drop(columns = ['customerID'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc_X = StandardScaler()\n",
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "X_train2.columns = X_train.columns.values\n",
    "X_train2.index = X_train.index.values\n",
    "X_train = X_train2\n",
    "\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))\n",
    "X_test2.columns = X_test.columns.values\n",
    "X_test2.index = X_test.index.values\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Section C: Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 15.1: Compare Baseline Classification Algorithms - First Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Using Accuracy and ROC AUC Mean Metrics\n",
    "\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append(('Logistic Regression', LogisticRegression(solver='liblinear', random_state = 0,\n",
    "                                                         class_weight='balanced')))\n",
    "\n",
    "models.append(('SVC', SVC(kernel = 'linear', random_state = 0)))\n",
    "\n",
    "\n",
    "models.append(('Kernel SVM', SVC(kernel = 'rbf', random_state = 0)))\n",
    "\n",
    "\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)))\n",
    "\n",
    "\n",
    "models.append(('Gaussian NB', GaussianNB()))\n",
    "\n",
    "\n",
    "models.append(('Decision Tree Classifier',\n",
    "               DecisionTreeClassifier(criterion = 'entropy', random_state = 0)))\n",
    "\n",
    "\n",
    "models.append(('Random Forest', RandomForestClassifier(\n",
    "    n_estimators=100, criterion = 'entropy', random_state = 0)))\n",
    "\n",
    "\n",
    "\n",
    "#Evaluating Model Results: \n",
    "\n",
    "    \n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "# set table to table to populate with performance results\n",
    "col = ['Algorithm', 'ROC AUC Mean', 'ROC AUC STD', \n",
    "       'Accuracy Mean', 'Accuracy STD']\n",
    "\n",
    "model_results = pd.DataFrame(columns=col)\n",
    "i = 0\n",
    "# evaluate each model using k-fold cross-validation\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(\n",
    "        n_splits=10, random_state=0, shuffle = True)  # 10-fold cross-validation\n",
    "\n",
    "    cv_acc_results = model_selection.cross_val_score(  # accuracy scoring\n",
    "        model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\n",
    "    cv_auc_results = model_selection.cross_val_score(  # roc_auc scoring\n",
    "        model, X_train, y_train, cv=kfold, scoring='roc_auc')\n",
    "\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    model_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "    \n",
    "model_results.sort_values(by=['ROC AUC Mean'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 15.2.  Visualize Classification Algorithms Accuracy Comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "#Using Accuracy Mean:\n",
    "    \n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(acc_results)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "\n",
    "\n",
    "#plt.ylabel('ROC AUC Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "#plt.xlabel('\\n Baseline Classification Algorithms\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Accuracy Score Comparison \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "#plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Area under ROC Curve:\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(auc_results)\n",
    "ax.set_xticklabels(names)\n",
    "\n",
    "\n",
    "#plt.ylabel('ROC AUC Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "#plt.xlabel('\\n Baseline Classification Algorithms\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('ROC AUC Comparison \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "#plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "#Compare Baseline Classification Algorithms - Second Iteration\n",
    "#Using Accuracy, Precision, Recall, F1 and F2 Score Metrics\n",
    "#-------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 15.3. Get the right parameters for the baseline models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Identify optimal number of K neighbors for KNN Model:\n",
    "\n",
    "\n",
    "score_array = []\n",
    "for each in range(1,25):\n",
    "    knn_loop = KNeighborsClassifier(n_neighbors = each) #set K neighbor as 3\n",
    "    knn_loop.fit(X_train,y_train)\n",
    "    score_array.append(knn_loop.score(X_test,y_test))\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(1,25),score_array, color = '#ec838a')\n",
    "\n",
    "\n",
    "plt.ylabel('Range\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Optimal Number of K Neighbors \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "#plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#optimal number of K neigbors = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify optimal number of trees for Random Forest Model:\n",
    " \n",
    "score_array = []\n",
    "for each in range(1,100):\n",
    "    rf_loop = RandomForestClassifier(n_estimators = each, random_state = 1) \n",
    "    rf_loop.fit(X_train,y_train)\n",
    "    score_array.append(rf_loop.score(X_test,y_test))\n",
    " \n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "plt.plot(range(1,100),score_array, color = '#ec838a')\n",
    "\n",
    "\n",
    "plt.ylabel('Range\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('Score\\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"large\", fontfamily = \"sans-serif\")\n",
    "plt.title('Optimal Number of Trees for Random Forest Model \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "#plt.legend(loc='top right', fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    " \n",
    " \n",
    "#Optimal number of decision trees = 72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 15.4. Compare Baseline Classification Algorithms - Second Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 15.4.1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fitting Logistic Regression to the Training set \n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "results = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.sort_values([\"Precision\", \n",
    "\"Recall\", \"F2 Score\"], ascending = False)\n",
    "print (results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 15.4.2. . Support Vector Machine (linear classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fitting SVM (SVC class) to the Training set:\n",
    "\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['SVM (Linear)', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "results = results.sort_values([\"Precision\", \n",
    "\"Recall\", \"F2 Score\"], ascending = False)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 15.4.3. K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Fitting KNN to the Training set:\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors = 22, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred  = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['K-Nearest Neighbours', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "results = results.sort_values([\"Precision\", \n",
    "\"Recall\", \"F2 Score\"], ascending = False)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 15.4.4.  Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fitting Kernel SVM to the Training set:\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['Kernel SVM', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "results = results.sort_values([\"Precision\", \n",
    "\"Recall\", \"F2 Score\"], ascending = False)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 15.4.5.  Naive Byes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fitting Naive Byes to the Training set:\n",
    "    \n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['Naive Byes', acc, prec, rec, f1, f2]],\n",
    "                columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "esults = results.sort_values([\"Precision\", \n",
    "\"Recall\", \"F2 Score\"], ascending = False)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 15.4.6. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Decision Tree to the Training set:\n",
    "\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['Decision Tree', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "results = results.sort_values([\"Precision\", \n",
    "\"Recall\", \"F2 Score\"], ascending = False)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 15.4.7. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest to the Training set:\n",
    "    \n",
    "classifier = RandomForestClassifier(n_estimators = 72, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "# Predicting the Test set results \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate results\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "model_results = pd.DataFrame([['Random Forest', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "results = results.append(model_results, ignore_index = True)\n",
    "\n",
    "results = results.sort_values([\"Precision\", \n",
    "\"Recall\", \"F2 Score\"], ascending = False)\n",
    "print (results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Section D: Model Improvement (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 16: Train & evaluate Chosen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Logistic Regression on the Training dataset:\n",
    "    \n",
    "classifier = LogisticRegression(random_state = 0, penalty = 'l2')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Predict the Test set results\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "\n",
    "#Evaluate Model Results on Test Set:\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred )\n",
    "prec = precision_score(y_test, y_pred )\n",
    "rec = recall_score(y_test, y_pred )\n",
    "f1 = f1_score(y_test, y_pred )\n",
    "f2 = fbeta_score(y_test, y_pred, beta=2.0)\n",
    "\n",
    "results = pd.DataFrame([['Logistic Regression', acc, prec, rec, f1, f2]],\n",
    "               columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score'])\n",
    "\n",
    "print (results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-check k-Fold Cross Validation:\n",
    "\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Logistic Regression Classifier Accuracy: %0.2f (+/- %0.2f)\"  % (accuracies.mean(), accuracies.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize results on a Confusion Matrix:\n",
    "    \n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (28,20))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g'#,cmap=\"YlGnBu\" \n",
    "           )\n",
    "class_names=[0,1]\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix\\n', y=1.1)\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "plt.ylabel('Actual label\\n')\n",
    "plt.xlabel('Predicted label\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using ROC Graph\n",
    "\n",
    "classifier.fit(X_train, y_train) \n",
    "probs = classifier.predict_proba(X_test) \n",
    "probs = probs[:, 1] \n",
    "classifier_roc_auc = accuracy_score(y_test, y_pred )\n",
    "\n",
    "\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, classifier.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot Logistic Regression ROC\n",
    "plt.plot(rf_fpr, rf_tpr, label='Logistic Regression (area = %0.2f)' % classifier_roc_auc)\n",
    "# Plot Base Rate ROC\n",
    "plt.plot([0,1], [0,1],label='Base Rate' 'k--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('True Positive Rate \\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"medium\", fontfamily = \"sans-serif\")\n",
    "plt.xlabel('\\nFalse Positive Rate \\n',horizontalalignment=\"center\",fontstyle = \"normal\", fontsize = \"medium\", fontfamily = \"sans-serif\")\n",
    "plt.title('ROC Graph \\n',horizontalalignment=\"center\", fontstyle = \"normal\", fontsize = \"22\", fontfamily = \"sans-serif\")\n",
    "plt.legend(loc=\"lower right\", fontsize = \"medium\")\n",
    "plt.xticks(rotation=0, horizontalalignment=\"center\")\n",
    "plt.yticks(rotation=0, horizontalalignment=\"right\")\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 17:Predict Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing Coefficients\n",
    "feature_importances = pd.concat([pd.DataFrame(dataset.drop(columns = 'customerID').columns, columns = [\"features\"]),\n",
    "           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n",
    "           ],axis = 1)\n",
    "\n",
    "feature_importances.sort_values(\"coef\", ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Section E: Future Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 19: Compare predictions against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revalidate final results with Confusion Matrix:\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "print (cm)\n",
    "#Confusion Matrix as a quick Crosstab:\n",
    "    \n",
    "pd.crosstab(y_test,pd.Series(y_pred),\n",
    "rownames=['ACTUAL'],colnames=['PRED'])\n",
    "#visualize Confusion Matrix:\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (28,20))\n",
    "fig, ax = plt.subplots()\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g'#,cmap=\"YlGnBu\" \n",
    "           )\n",
    "class_names=[0,1]\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix\\n', y=1.1)\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.ylabel('Actual label\\n')\n",
    "plt.xlabel('Predicted label\\n')\n",
    "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 20: Format Final Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = pd.concat([test_identity, y_test], axis = 1).dropna()\n",
    "\n",
    "final_results['predictions'] = y_pred \n",
    "\n",
    "final_results[\"propensity_to_convert(%)\"] = probs \n",
    "\n",
    "final_results[\"propensity_to_convert(%)\"] = final_results[\"propensity_to_convert(%)\"]*100\n",
    "\n",
    "final_results[\"propensity_to_convert(%)\"] = final_results[\"propensity_to_convert(%)\"].round(2)\n",
    "\n",
    "final_results = final_results[['customerID', 'Churn', 'predictions', 'propensity_to_convert(%)']]\n",
    "\n",
    "final_results ['Ranking'] = pd.qcut(final_results['propensity_to_convert(%)'].rank(method = 'first'),10,labels=range(10,0,-1))\n",
    "\n",
    "print (final_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "4c9960f903948092c111fd1da4ed0a7aecc4afac3cee1c1d5130c55e4ff8067f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
